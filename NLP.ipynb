{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b84b18",
   "metadata": {},
   "source": [
    "#### 0. Prepare Pkgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce1ccfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# it seems to have some dependency issue with Torch using CPU only\n",
    "# so I uninstalled Torch on pip\n",
    "# then it is back by Tensorflow\n",
    "# Better idea to create a new environment\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.util import minibatch\n",
    "from spacy.training.example import Example\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import Markdown, Latex, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff107ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy relies on language-specific models\n",
    "# nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ba7eef",
   "metadata": {},
   "source": [
    "#### 1. Basic Text Processing with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3149805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews on menu items\n",
    "# prepare data\n",
    "data = pd.read_json('Documents/restaurant.json')\n",
    "data.head()\n",
    "menu = [\"Cheese Steak\", \"Cheesesteak\", \"Steak and Cheese\", \"Italian Combo\", \"Tiramisu\", \"Cannoli\",\n",
    "        \"Chicken Salad\", \"Chicken Spinach Salad\", \"Meatball\", \"Pizza\", \"Pizzas\", \"Spaghetti\",\n",
    "        \"Bruchetta\", \"Eggplant\", \"Italian Beef\", \"Purista\", \"Pasta\", \"Calzones\",  \"Calzone\",\n",
    "        \"Italian Sausage\", \"Chicken Cutlet\", \"Chicken Parm\", \"Chicken Parmesan\", \"Gnocchi\",\n",
    "        \"Chicken Pesto\", \"Turkey Sandwich\", \"Turkey Breast\", \"Ziti\", \"Portobello\", \"Reuben\",\n",
    "        \"Mozzarella Caprese\",  \"Corned Beef\", \"Garlic Bread\", \"Pastrami\", \"Roast Beef\",\n",
    "        \"Tuna Salad\", \"Lasagna\", \"Artichoke Salad\", \"Fettuccini Alfredo\", \"Chicken Parmigiana\",\n",
    "        \"Grilled Veggie\", \"Grilled Veggies\", \"Grilled Vegetable\", \"Mac and Cheese\", \"Macaroni\",\n",
    "        \"Prosciutto\", \"Salami\"]\n",
    "\n",
    "# phrase matcher\n",
    "nlp = spacy.blank('en')  # use empty model?\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "menu_token_list = [nlp(item) for item in menu]\n",
    "matcher.add('MENU', menu_token_list)\n",
    "\n",
    "# prepare a defaultdict to store ratings of menu items\n",
    "item_ratings = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e71ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize - matcher - append\n",
    "for idx, review in data.iterrows():\n",
    "    doc = nlp(review.text)\n",
    "    matches = matcher(doc)\n",
    "    # every match has three comps: [0] = id, [1] = start, [2] = end\n",
    "    found_items = set([doc[match[1]:match[2]].text.lower()\n",
    "                       for match in matches])  # lower to lemmatize\n",
    "    for f in found_items:\n",
    "        item_ratings[f].append(review.stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e14d7a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    pizza  265\n",
      "                    pasta  206\n",
      "                 meatball  128\n",
      "              cheesesteak   97\n",
      "             cheese steak   76\n",
      "                  cannoli   72\n",
      "                  calzone   72\n",
      "                 eggplant   69\n",
      "                  purista   63\n",
      "                  lasagna   59\n",
      "          italian sausage   53\n",
      "               prosciutto   50\n",
      "             chicken parm   50\n",
      "             garlic bread   39\n",
      "                  gnocchi   37\n",
      "                spaghetti   36\n",
      "                 calzones   35\n",
      "                   pizzas   32\n",
      "                   salami   28\n",
      "            chicken pesto   27\n",
      "             italian beef   25\n",
      "                 tiramisu   21\n",
      "            italian combo   21\n",
      "                     ziti   21\n",
      "         chicken parmesan   19\n",
      "       chicken parmigiana   17\n",
      "               portobello   14\n",
      "           mac and cheese   11\n",
      "           chicken cutlet   10\n",
      "         steak and cheese    9\n",
      "                 pastrami    9\n",
      "               roast beef    7\n",
      "       fettuccini alfredo    6\n",
      "           grilled veggie    6\n",
      "          turkey sandwich    5\n",
      "               tuna salad    5\n",
      "          artichoke salad    5\n",
      "                 macaroni    5\n",
      "            chicken salad    5\n",
      "                   reuben    4\n",
      "    chicken spinach salad    2\n",
      "              corned beef    2\n",
      "            turkey breast    1\n"
     ]
    }
   ],
   "source": [
    "# mean ratings\n",
    "mean_ratings = {item: sum(val)/len(val) for item, val in item_ratings.items()}\n",
    "\n",
    "# but count matters\n",
    "counts = {item: len(val) for item, val in item_ratings.items()}\n",
    "item_counts = sorted(counts, key=counts.get, reverse=True)\n",
    "for item in item_counts:\n",
    "    print(f\"{item:>25}{counts[item]:>5}\")  # indent {item:>25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e0c0a1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Worst rated menu items**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chicken cutlet       Ave rating:3.40 \tcount:10\n",
      "turkey sandwich      Ave rating:3.80 \tcount:5\n",
      "spaghetti            Ave rating:3.89 \tcount:36\n",
      "italian beef         Ave rating:3.92 \tcount:25\n",
      "tuna salad           Ave rating:4.00 \tcount:5\n",
      "macaroni             Ave rating:4.00 \tcount:5\n",
      "italian combo        Ave rating:4.05 \tcount:21\n",
      "garlic bread         Ave rating:4.13 \tcount:39\n",
      "roast beef           Ave rating:4.14 \tcount:7\n",
      "eggplant             Ave rating:4.16 \tcount:69\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "**Best rated menu items**\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corned beef          Ave ratings:5.00 \tcount:2\n",
      "turkey breast        Ave ratings:5.00 \tcount:1\n",
      "fettuccini alfredo   Ave ratings:5.00 \tcount:6\n",
      "artichoke salad      Ave ratings:5.00 \tcount:5\n",
      "steak and cheese     Ave ratings:4.89 \tcount:9\n",
      "reuben               Ave ratings:4.75 \tcount:4\n",
      "prosciutto           Ave ratings:4.68 \tcount:50\n",
      "purista              Ave ratings:4.67 \tcount:63\n",
      "chicken salad        Ave ratings:4.60 \tcount:5\n",
      "chicken pesto        Ave ratings:4.56 \tcount:27\n"
     ]
    }
   ],
   "source": [
    "# combine ratings and counts\n",
    "sorted_ratings = sorted(mean_ratings, key=mean_ratings.get)\n",
    "display(Markdown('**Worst rated menu items**\\n'))\n",
    "for item in sorted_ratings[:10]:\n",
    "    print(\n",
    "        f\"{item:20} Ave rating:{mean_ratings[item]:.2f} \\tcount:{counts[item]}\")\n",
    "\n",
    "display(Markdown('\\n\\n**Best rated menu items**\\n'))\n",
    "for item in sorted_ratings[:-11:-1]:\n",
    "    print(\n",
    "        f'{item:20} Ave ratings:{mean_ratings[item]:.2f} \\tcount:{counts[item]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57623c31",
   "metadata": {},
   "source": [
    "#### 2. Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fccf34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spam detection\n",
    "spam = pd.read_csv('Documents/spam.csv')\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5dd9f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "  {'cats': {'ham': True, 'spam': False}}),\n",
       " ('Ok lar... Joking wif u oni...', {'cats': {'ham': True, 'spam': False}}),\n",
       " (\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       "  {'cats': {'ham': False, 'spam': True}})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a pipe\n",
    "nlp = spacy.blank('en')\n",
    "textcat = nlp.add_pipe('textcat')\n",
    "\n",
    "# add labels to text classifier\n",
    "textcat.add_label('ham')\n",
    "textcat.add_label('spam')\n",
    "\n",
    "# convert labels in the data to the form TextCategorizer requires\n",
    "# (1/2) aka. dictionary of boolean values for each class\n",
    "train_texts = spam['text'].values\n",
    "train_labels = [{'cats': {'ham': label == 'ham',\n",
    "                         'spam': label == 'spam'}}\n",
    "                for label in spam['label']]\n",
    "\n",
    "# (2/2) combine text and labels into a single list\n",
    "train_data = list(zip(train_texts, train_labels))\n",
    "train_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a661584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "# (1/3) create an optimizer to update the model\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "# (2/3) create minibatches since more efficient \n",
    "batches = minibatch(train_data, size = 8)\n",
    "\n",
    "# (3/3) split batch into text & labels, update model\n",
    "for batch in batches:\n",
    "    for text, labels in batch:\n",
    "        doc = nlp.make_doc(text)\n",
    "        example = Example.from_dict(doc, labels)\n",
    "        nlp.update([example], sgd = optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8565833a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'textcat': 293.82070328966967}\n",
      "{'textcat': 406.4270003403468}\n",
      "{'textcat': 488.70290066040826}\n",
      "{'textcat': 544.8554215435448}\n",
      "{'textcat': 575.8179430301309}\n"
     ]
    }
   ],
   "source": [
    "# more epoches\n",
    "random.seed(1)\n",
    "spacy.util.fix_random_seed(1)\n",
    "optimizer = nlp.begin_training()  # only use when training from scratch\n",
    "\n",
    "losses = {}\n",
    "for epoch in range(5):\n",
    "    random.shuffle(train_data)\n",
    "    batches = minibatch(train_data, size=8)\n",
    "    for batch in batches:\n",
    "        for text, labels in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, labels)\n",
    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1770cc53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham', 'spam']\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "# tokenize texts\n",
    "texts = [\"Are you ready for the tea party??? It's gonna be wild\",\n",
    "        \"URGENT reply to this message for GUARANTEED FREE TEA\"]\n",
    "docs = [nlp.tokenizer(text) for text in texts]\n",
    "\n",
    "# use textcat to get scores for each doc\n",
    "textcat = nlp.get_pipe('textcat') # trained \n",
    "scores = textcat.predict(docs)\n",
    "\n",
    "# use highest prob score to get pred. label\n",
    "predicted_labels = scores.argmax(axis = 1)\n",
    "print([textcat.labels[label] for label in predicted_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470c0ba7",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3. Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a5bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d8e9fe",
   "metadata": {},
   "source": [
    "###### <font color ='7f7f7f'>classification</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca86016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make doc vecs\n",
    "spam = pd.read_csv('Documents/spam.csv')\n",
    "\n",
    "with nlp.disable_pipes():  # for efficiency\n",
    "    doc_vectors = np.array([nlp(text).vector for text in spam.text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce01107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.849%\n"
     ]
    }
   ],
   "source": [
    "# classification model with SVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    doc_vectors, spam.label, test_size=.1, random_state=1)\n",
    "\n",
    "# dual = False to save time\n",
    "svc = LinearSVC(random_state=1, dual=False, max_iter=10000)\n",
    "svc.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {svc.score(X_test,y_test)*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ace354",
   "metadata": {},
   "source": [
    "###### <font color ='7f7f7f'>doc similarity</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be071fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7030031"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measure doc similarity with cosine similarity\n",
    "def cosine_similarity(a, b):\n",
    "    return a.dot(b)/np.sqrt(a.dot(a)*b.dot(b))\n",
    "\n",
    "\n",
    "a = nlp('REPLY NOW FOR FREE TEA').vector\n",
    "b = nlp('According to legend, Emperor Shen Nung discovered tea when leaves from a wild tree blew into his pot of boiling water.').vector\n",
    "cosine_similarity(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94a2b3",
   "metadata": {},
   "source": [
    "#### Appendices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa40a98",
   "metadata": {},
   "source": [
    "###### <font color = '7f7f7f'>text classification with train/test split & functions</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94fd25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(csv_file, split=.9):\n",
    "    data = pd.read_csv(csv_file)\n",
    "    # shuffle data\n",
    "    train_data = data.sample(frac=1, random_state=7)\n",
    "    texts = train_data.text.values\n",
    "    labels = [{'ham': label == 'ham', 'spam': label == 'spam'}\n",
    "              for label in train_data['label']]\n",
    "    split = int(len(train_data)*split)\n",
    "\n",
    "    train_labels = [{'cats': labels} for labels in labels[:split]]\n",
    "    test_labels = [{'cats': labels} for labels in labels[split:]]\n",
    "    return texts[:split], train_labels, texts[split:], test_labels\n",
    "\n",
    "\n",
    "train_texts, train_labels, test_texts, test_labels = load_data(\n",
    "    'Documents/spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "754121ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts from training data\n",
      "------\n",
      "['You will be in the place of that man'\n",
      " '\\\\Si.como no?!listened2the plaid album-quite gd&the new air1 which is hilarious-also boughtåÓbraindanceåÓa comp.ofstuff on aphexåÕs ;abel']\n",
      "\n",
      "Labels from training data\n",
      "------\n",
      "[{'cats': {'ham': True, 'spam': False}}, {'cats': {'ham': True, 'spam': False}}]\n"
     ]
    }
   ],
   "source": [
    "print('Texts from training data\\n------')\n",
    "print(train_texts[:2])\n",
    "print('\\nLabels from training data\\n------')\n",
    "print(train_labels[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdcabfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the model\n",
    "nlp = spacy.blank('en')\n",
    "textcat = nlp.add_pipe('textcat')\n",
    "\n",
    "textcat.add_label('ham')\n",
    "textcat.add_label('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a56a7505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253.89666720109636\n"
     ]
    }
   ],
   "source": [
    "# train function\n",
    "def train(model, train_data, optimizer, batch_size=8):\n",
    "    losses = {}\n",
    "    random.seed(1)\n",
    "    random.shuffle(train_data)\n",
    "    for batch in minibatch(train_data, size=batch_size):\n",
    "        for text, labels in batch:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, labels)\n",
    "            model.update([example], sgd=optimizer, losses=losses)\n",
    "    return losses\n",
    "\n",
    "\n",
    "spacy.util.fix_random_seed(1)\n",
    "random.seed(1)\n",
    "optimizer = nlp.begin_training()\n",
    "train_data = list(zip(train_texts, train_labels))\n",
    "losses = train(nlp, train_data, optimizer)\n",
    "print(losses['textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e000eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "def predict(nlp, texts):\n",
    "    docs = [nlp.tokenizer(text) for text in texts]\n",
    "    textcat = nlp.get_pipe('textcat')\n",
    "    scores = textcat.predict(docs)\n",
    "    predicted_class = scores.argmax(axis=1)\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cc21abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9839\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model by accuracy\n",
    "def evaluate(model, texts, labels):\n",
    "    predicted_class = predict(model, texts)\n",
    "    true_class = [int(label['cats']['spam']) for label in labels]\n",
    "    correct_predictions = predicted_class == true_class\n",
    "    return correct_predictions.mean()\n",
    "\n",
    "\n",
    "accuracy = evaluate(nlp, test_texts, test_labels)\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1482f01e",
   "metadata": {},
   "source": [
    "###### <font color = 'maroon'>small project about Su & Lu</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8f0df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# pkgs for this project per se\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.util import minibatch\n",
    "from spacy.training.example import Example\n",
    "import random\n",
    "\n",
    "# below are for word2vec\n",
    "from opencc import OpenCC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import defaultdict\n",
    "\n",
    "cc = OpenCC('t2s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d632555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data https://raw.githubusercontent.com/chinese-poetry/chinese-poetry/master/json/\n",
    "# Su @ 14: 44000, 45000, 46000\n",
    "# Lu @ 39-41: 127000 - 136000\n",
    "def load_song_shi(nums):\n",
    "    dfs = pd.concat([pd.read_json(\n",
    "        'https://raw.githubusercontent.com/chinese-poetry/chinese-poetry/master/json/poet.song.{}.json'.format(num)) for num in nums])\n",
    "    return dfs\n",
    "\n",
    "\n",
    "Su = load_song_shi([44000, 45000, 46000])\n",
    "Lu = load_song_shi(list(range(127000, 137000, 1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51476dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.util.fix_random_seed(1)\n",
    "random.seed(1)\n",
    "\n",
    "# to same length\n",
    "Su = Su[Su.author == '蘇軾']\n",
    "Lu = Lu[Lu.author == '陸游'].sample(n=len(Su))\n",
    "\n",
    "# turn list object to string\n",
    "Su['paragraphs'] = Su['paragraphs'].apply(\n",
    "    lambda x: ''.join(line for line in x))\n",
    "\n",
    "Lu['paragraphs'] = Lu['paragraphs'].apply(\n",
    "    lambda x: ''.join(line for line in x))\n",
    "SuLu = pd.concat([Su, Lu]).sample(frac=1, random_state=7).reset_index().drop(columns = ['index'])\n",
    "authors = SuLu.author.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b264f23f",
   "metadata": {},
   "source": [
    "######    <font color = 'teal'>simplify to use language model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e441c083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.566%\n"
     ]
    }
   ],
   "source": [
    "SuLu['paragraphs'] = SuLu['paragraphs'].apply(lambda x: cc.convert(x))\n",
    "\n",
    "model = spacy.load('zh_core_web_lg')\n",
    "with model.disable_pipes():\n",
    "    doc_vectors = np.array([model(text).vector for text in SuLu.paragraphs])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    doc_vectors, SuLu.author, test_size=.1, random_state=1)\n",
    "\n",
    "# dual = False to save time\n",
    "svc = LinearSVC(random_state=1, dual=False, max_iter=10000)\n",
    "svc.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {svc.score(X_test,y_test)*100:.3f}%\")  # OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e9a1ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:00:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.0/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 72.035%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    doc_vectors, SuLu.author, test_size=.1, random_state=1)\n",
    "\n",
    "# dual = False to save time\n",
    "xgb = XGBClassifier(random_state=1)\n",
    "xgb.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {xgb.score(X_test,y_test)*100:.3f}%\")  # OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acef64a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 67.611%\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    doc_vectors, SuLu.author, test_size=.1, random_state=1)\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=1)\n",
    "rfc.fit(X_train, y_train)\n",
    "print(f\"Accuracy: {rfc.score(X_test,y_test)*100:.3f}%\")  # Not good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67ca122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "author                                                      陸游\n",
      "paragraphs    前年蒙趣召，渡江当六月。顾惭衰病躯，触热朝行阙。君恩虽屡下，恐惧乞骸骨。飘然返柴荆，所愧已黔突。\n",
      "Name: 1100, dtype: object author                                                       蘇軾\n",
      "paragraphs    任公镇西南，尝赠绕朝策。当时若尽用，善阵无赫赫。凄凉十年后，邪正久已白。却留封德彝，天意眇难...\n",
      "Name: 3918, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# doc similarity\n",
    "def cosine_similarity(a, b):\n",
    "    return a.dot(b)/np.sqrt(a.dot(a)*b.dot(b))\n",
    "# center \n",
    "vec_mean = doc_vectors.mean(axis = 0)\n",
    "centered = doc_vectors - vec_mean\n",
    "\n",
    "sel = random.randint(0,len(doc_vectors))\n",
    "line = doc_vectors[sel]\n",
    "val = {}\n",
    "range_ = list(range(sel)) + list(range(sel+1, len(doc_vectors)))\n",
    "for i in range_:\n",
    "    val[i] = cosine_similarity(doc_vectors[i], line)\n",
    "\n",
    "print(SuLu.iloc[sel][['author','paragraphs']],SuLu.iloc[sorted(val, key = val.get, reverse = True)[0]][['author','paragraphs']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee1932ec",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c39fe0ef821e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mrange_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_vectors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc_vectors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrange_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmost_similar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0msims\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# which poem is most \"most similar\" to others in the df\n",
    "sims = defaultdict(int)\n",
    "for idx in range(len(doc_vectors)):\n",
    "    range_ = list(range(idx)) + list(range(idx+1, len(doc_vectors)))\n",
    "    sim = np.array([cosine_similarity(doc_vectors[idx], c) for c in doc_vectors[range_]])\n",
    "    most_similar = sim.argmax()\n",
    "    sims[most_similar] = sims[most_similar] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "126aaba3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ca0dcb1e9063>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# most \"most similar\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mSuLu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msims\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# 5596\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# most \"most similar\"\n",
    "SuLu.iloc[sorted(sims, key = sims.get, reverse = True)[0]] # 5596"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13587c92",
   "metadata": {},
   "source": [
    "###### <font color = '7f7f7f'>end of simplification</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train/test\n",
    "train_texts = SuLu.paragraphs.values\n",
    "authors_label = [{authors[0]: author == authors[0], authors[1]: author == authors[1]}\n",
    "                 for author in SuLu['author']]\n",
    "split = .9\n",
    "split = int(len(SuLu)*split)\n",
    "\n",
    "train_authors = [{'cats': author} for author in authors_label[:split]]\n",
    "test_authors = [{'cats': author} for author in authors_label[split:]]\n",
    "train_texts = SuLu.paragraphs[:split]\n",
    "test_texts = SuLu.paragraphs[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d810fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2174.827909047634\n",
      "1178.7452880896647\n",
      "811.5390418922483\n",
      "595.4171474424583\n",
      "390.694593819601\n",
      "336.3565853438324\n",
      "296.30636926735184\n",
      "191.57716236540728\n",
      "184.13119991794198\n",
      "171.50943364577017\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "nlp = spacy.blank('zh')\n",
    "textcat = nlp.add_pipe('textcat')\n",
    "textcat.add_label(authors[0])  # Su\n",
    "textcat.add_label(authors[1])  # Lu\n",
    "\n",
    "# train\n",
    "optimizer = nlp.begin_training()\n",
    "train_data = list(zip(train_texts, train_authors))\n",
    "for epoch in range(10):\n",
    "    losses = {}\n",
    "    random.seed(1)\n",
    "    random.shuffle(train_data)\n",
    "    for batches in minibatch(train_data, size=8):\n",
    "        for text, labels in batches:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, labels)\n",
    "            nlp.update([example], sgd=optimizer, losses=losses)\n",
    "    print(losses['textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57c2435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4301\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "def predict(nlp, texts):\n",
    "    docs = [nlp.tokenizer(text) for text in texts]\n",
    "    textcat = nlp.get_pipe('textcat')\n",
    "    scores = textcat.predict(docs)\n",
    "    predicted_class = scores.argmax(axis=1)\n",
    "    return predicted_class\n",
    "\n",
    "def evaluate(model, texts, labels):\n",
    "    predicted_class = predict(model, texts)\n",
    "    true_class = [int(label == authors[1]) for label in labels]\n",
    "    correct_predictions = predicted_class == true_class\n",
    "    return correct_predictions.mean()\n",
    "\n",
    "accuracy = evaluate(nlp, test_texts, test_authors)\n",
    "print(f'Accuracy: {accuracy:.4f}') # rather poor accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
